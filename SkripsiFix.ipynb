{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149f6b4c",
   "metadata": {},
   "source": [
    "# Model MLP-CNN untuk Rekonstruksi Citra pada Sistem Continuous Wave Diffuse Optical Tomography (CW-DOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150a757",
   "metadata": {},
   "source": [
    "## Mengimpor semua library yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd194690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from io import BytesIO\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.image import ssim\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36da480",
   "metadata": {},
   "source": [
    "## Memuat dan mempses semua dataset yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3021ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder1_path = \"-\"\n",
    "folder2_path = \"-\"\n",
    "foldergmb2_path = \"-\"\n",
    "\n",
    "# Load file Excel (anomali), Kode untuk memuat data bisa disesuaikan untuk lokal atau bukan\n",
    "G1_list = []\n",
    "# epsilon = 1e-6\n",
    "for file_name in os.listdir(folder1_path):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder1_path, file_name)\n",
    "        data = pd.read_excel(file_path, header=None).to_numpy().flatten()\n",
    "        data_scaled = (data - np.mean(data)) / np.mean(data)\n",
    "        data_norm = data_scaled/np.max(data_scaled)\n",
    "        G1_list.append(data_norm.reshape(-1, 1))\n",
    "G1 = np.array(G1_list).squeeze()\n",
    "\n",
    "# --- Muat Gambar Objek Asli (Persiapan Data) ---\n",
    "image2_list = []\n",
    "try:\n",
    "    if not os.path.exists(folder2_path) or not os.listdir(folder2_path):\n",
    "        raise FileNotFoundError(\"Folder tidak ditemukan atau kosong.\")\n",
    "\n",
    "    for filename in sorted(os.listdir(folder2_path)):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(folder2_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Pastikan RGB\n",
    "                img = cv2.resize(img, (100, 100))        # Sesuaikan ukuran (sesuai kebutuhan)\n",
    "                img = img / 255.0                        # Normalisasi ke 0-1\n",
    "                image2_list.append(img)\n",
    "    if not image2_list:\n",
    "        raise ValueError(\"Tidak ada gambar yang valid ditemukan di folder.\")\n",
    "\n",
    "    image2_array = np.array(image2_list)\n",
    "    print(f\"Dimuat {len(image2_list)} gambar dari '{folder2_path}'. Bentuk: {image2_array.shape}\")\n",
    "\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Error: {e}. Membuat dummy image2_array untuk demonstrasi.\")\n",
    "    # Fallback: Buat dummy data jika tidak ada gambar\n",
    "    num_dummy_images = 3\n",
    "    image2_array = np.random.rand(num_dummy_images, 100, 100, 3).astype(np.float32)\n",
    "    print(f\"Dummy image2_array dibuat dengan bentuk: {image2_array.shape}\")\n",
    "\n",
    "# --- Proses Konversi Gambar ke Hitam Putih (Biner) ---\n",
    "binary_images_list = []\n",
    "threshold_value = 0.1 # Nilai threshold (antara 0.0 - 1.0). Sesuaikan jika perlu.\n",
    "\n",
    "for img_rgb_normalized in image2_array:\n",
    "    # 1. Konversi ke Skala Abu-abu (menggunakan bobot umum)\n",
    "    grayscale_img = (0.2989 * img_rgb_normalized[:, :, 0] +\n",
    "                     0.5870 * img_rgb_normalized[:, :, 1] +\n",
    "                     0.1140 * img_rgb_normalized[:, :, 2])\n",
    "\n",
    "    # 2. Terapkan Thresholding untuk membuat gambar biner (hitam/putih)\n",
    "    # Piksel > threshold_value menjadi 1 (putih), lainnya 0 (hitam)\n",
    "    binary_img = (grayscale_img > threshold_value).astype(np.float32)\n",
    "    binary_images_list.append(binary_img)\n",
    "\n",
    "binary_images_array = np.array(binary_images_list)\n",
    "\n",
    "print(f\"Bentuk array gambar biner yang dihasilkan: {binary_images_array.shape}\")\n",
    "\n",
    "# --- Tampilkan Hasil (Hanya Beberapa Contoh) ---\n",
    "# Tampilkan maksimal 3 pasang gambar untuk ilustrasi\n",
    "# num_display = min(3, len(image2_array))\n",
    "\n",
    "# plt.figure(figsize=(num_display * 5, 8))\n",
    "\n",
    "# for i in range(num_display):\n",
    "#     # Gambar Asli (Berwarna)\n",
    "#     plt.subplot(2, num_display, i + 1)\n",
    "#     plt.imshow(image2_array[i])\n",
    "#     plt.title(f'Asli {i+1}')\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     # Gambar Hitam Putih (Biner)\n",
    "#     plt.subplot(2, num_display, i + 1 + num_display)\n",
    "#     plt.imshow(binary_images_array[i], cmap='gray') # Penting: gunakan cmap='gray'\n",
    "#     plt.title(f'Biner {i+1} (Th: {threshold_value:.2f})')\n",
    "#     plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Load gambar (Linear Satu Langkah)\n",
    "image3_list = []\n",
    "for filename in sorted(os.listdir(foldergmb2_path)):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(foldergmb2_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (100, 100)) # aslinya adalah (100, 100)\n",
    "        img = img / 255.0\n",
    "        if img is not None:\n",
    "            image3_list.append(img)\n",
    "image3_array = np.array(image3_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcfb0f",
   "metadata": {},
   "source": [
    "Membagi semua dataset menjadi data latih dan data uji dengan perbandingan 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Persiapan Data Latih dan Data Uji untuk model\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(G1, binary_images_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# ### Persiapan untuk membandingkan dengan data rekonstruksi Linear Satu Langkah\n",
    "# X_train2, X_test2, Y_train2, Y_test2 = train_test_split(image_array, image2_array, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train1 = np.expand_dims(X_train1, axis=-1)\n",
    "X_test1 = np.expand_dims(X_test1, axis=-1)\n",
    "Y_train1 = np.expand_dims(Y_train1, axis=-1)\n",
    "Y_test1 = np.expand_dims(Y_test1, axis=-1)\n",
    "# print(X_train1.shape)\n",
    "# print(X_test1.shape)\n",
    "# print(Y_train1.shape)\n",
    "# print(Y_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368091f",
   "metadata": {},
   "source": [
    "## Arsitektur, Pelatihan, dan Optimasi Model yang digunakan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6172d2",
   "metadata": {},
   "source": [
    "Model yang digunakan adalah kombinasi dari MLP (Multi-Layer Perceptn) dan CNN (Convolutional Neural Network)\n",
    "\n",
    "MLP --> digunakan untuk mempses/mengonversi data distribusi intensitas cahaya menjadi sebuah sketsa gambar awal berdasarkan data label/data gambar objek asli yang digunakan\n",
    "\n",
    "CNN --> digunakan untuk merekonstruksi dan mempercantik gambar yang dihasilkan berdasarkan keluaran dari MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a85519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensi input dan output\n",
    "num_input_features = 256  # Input\n",
    "image_shape = (100, 100,1)  # Target gambar\n",
    "\n",
    "# 1. MLP, layer dan neuron bisa diatur sesuai dengan kebutuhan\n",
    "def build_mlp(input_dim, latent_dim):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(2048, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(latent_dim[0] * latent_dim[1] * latent_dim[2], activation='relu')(x)\n",
    "    outputs = layers.Reshape(latent_dim)(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# 2. CNN, layer dan neuron bisa diatur sesuai dengan kebutuhan\n",
    "def build_cnn(latent_dim, output_shape):\n",
    "    inputs = layers.Input(shape=latent_dim)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Cropping2D(((2,2), (2,2)))(x)\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), strides=1, padding='same', activation='sigmoid')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# 3. Bangun Model MLP + CNN\n",
    "latent_dim = (13, 13, 128)  # Bentuk cetak biru yang akan dihasilkan oleh MLP\n",
    "mlp_encoder = build_mlp(num_input_features, latent_dim)\n",
    "cnn_decoder = build_cnn(latent_dim, image_shape)\n",
    "\n",
    "# 4. Hubungkan MLP dan CNN\n",
    "inputs = layers.Input(shape=(num_input_features,))\n",
    "latent_output = mlp_encoder(inputs)\n",
    "outputs = cnn_decoder(latent_output)\n",
    "\n",
    "vgg = VGG19(weights=\"imagenet\", include_top=False)\n",
    "vgg.trainable = False\n",
    "loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block3_conv3\").output)\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    y_true_rgb = tf.image.grayscale_to_rgb(y_true)\n",
    "    y_pred_rgb = tf.image.grayscale_to_rgb(y_pred)\n",
    "    return tf.reduce_mean(tf.abs(loss_model(y_true_rgb) - loss_model(y_pred_rgb)))\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return 0.4 * tf.keras.losses.MeanSquaredError()(y_true, y_pred) + 0.3 * ssim_loss(y_true, y_pred) +  0.3 * perceptual_loss(y_true, y_pred)\n",
    "\n",
    "# **4. Compile Model**\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss=combined_loss, metrics=['mse'])  # Bisa pakai loss lain seperti SSIM jika ingin kualitas gambar lebih baik\n",
    "\n",
    "# **5. Cek Arsitektur Model**\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a35b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback untuk mengurangi learning rate saat val_loss stagnan\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, verbose=1\n",
    ")\n",
    "\n",
    "# Callback untuk menghentikan training jika tidak ada perbaikan\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# Training model, parameter di bawah ini bisa diatur sesuai kebutuhan\n",
    "history = model.fit(\n",
    "    X_train1, Y_train1,\n",
    "    epochs=75,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[lr_scheduler, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5347d0",
   "metadata": {},
   "source": [
    "## Hasil dari model yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbe79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi gambar, ganti cmap=gray jika ingin gambar grayscale dan ganti cmap=jet jika ingin gambar berwarna\n",
    "num_samples = 15\n",
    "X_test_sample = X_test1[:num_samples]  # Contoh data input\n",
    "Y_test_sample = Y_test1[:num_samples]\n",
    "Y_pred_sample = model.predict(X_test1)\n",
    "\n",
    "# print(Y_test_sample.shape)\n",
    "# print(Y_pred_sample.shape)\n",
    "\n",
    "# Tampilkan hasilnya\n",
    "fig, axes = plt.subplots(num_samples, 2, figsize=(10, 2 * num_samples))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    true_img = Y_test_sample[i]\n",
    "    pred_img = Y_pred_sample[i]\n",
    "\n",
    "    # Gambar asli (target)\n",
    "    axes[i, 0].imshow(true_img, cmap='gray') # Ganti dengan cmap='jet' jika ingin berwarna\n",
    "    axes[i, 0].set_title(\"Target (Asli)\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    \n",
    "    # Gambar hasil prediksi\n",
    "    axes[i, 1].imshow(pred_img, cmap='gray')\n",
    "    axes[i, 1].set_title(\"Prediksi (Model)\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba77ab",
   "metadata": {},
   "source": [
    "Grafik penurunan loss dan MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a371be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot MSE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mse'], label='Training MSE', color='green')\n",
    "plt.plot(history.history['val_mse'], label='Validation MSE', color='red')\n",
    "plt.title('MSE vs. Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Err')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1407fb",
   "metadata": {},
   "source": [
    "Hasil metrik SSIM dan PSNR beserta grafik distribusinya (lebih baik ganti PSNR dengan Dice Coefficient atau DSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad375909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "for y_true, y_pred in zip(Y_test1, Y_pred_sample):\n",
    "    ssim_score = ssim(y_true, y_pred, channel_axis=-1, data_range=1.0, win_size=11)\n",
    "    psnr_score = psnr(y_true, y_pred, data_range=1.0)\n",
    "    \n",
    "    ssim_scores.append(ssim_score)\n",
    "    psnr_scores.append(psnr_score)\n",
    "\n",
    "print(\"Average SSIM:\", np.mean(ssim_scores))\n",
    "print(\"Average PSNR:\", np.mean(psnr_scores))\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ssim_scores, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribusi SSIM\")\n",
    "plt.xlabel(\"SSIM\")\n",
    "plt.ylabel(\"Frekuensi\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(psnr_scores, bins=20, color='salmon', edgecolor='black')\n",
    "plt.title(\"Distribusi PSNR\")\n",
    "plt.xlabel(\"PSNR (dB)\")\n",
    "plt.ylabel(\"Frekuensi\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a246b7",
   "metadata": {},
   "source": [
    "## Perbandingan hasil antara Linear Satu Langkah dan MLP-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples     = 15\n",
    "X_test_sample   = X_test1[:num_samples]\n",
    "Y_true_sample   = Y_test1[:num_samples]     # gambar asli (target)\n",
    "Y_lin_sample    = Y_test2[:num_samples]     # rekonstruksi linear 1 langkah\n",
    "Y_pred_sample   = model.predict(X_test_sample)[:num_samples]   # prediksi MLP‑CNN\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Plot 3 kolom  (Asli | Linear 1 Langkah | Prediksi)\n",
    "# -------------------------------------------------\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 3 * num_samples))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # ---- kolom 0: gambar asli ----\n",
    "    axes[i, 0].imshow(np.clip(Y_true_sample[i], 0, 1))\n",
    "    axes[i, 0].set_title(\"Target (Asli)\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    # ---- kolom 1: linear 1 langkah ----\n",
    "    axes[i, 1].imshow(np.clip(Y_lin_sample[i], 0, 1))\n",
    "    axes[i, 1].set_title(\"Linear 1 Langkah\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "    # ---- kolom 2: prediksi MLP-CNN ----\n",
    "    axes[i, 2].imshow(np.clip(Y_pred_sample[i], 0, 1))\n",
    "    axes[i, 2].set_title(\"Prediksi MLP‑CNN\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "\n",
    "# Rapikan spasi antarkolom\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9eb19",
   "metadata": {},
   "source": [
    "## Menyimpan dan Memuat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan Model\n",
    "model.save('-')  # Format HDF5 atau Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc298a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat model untuk format Keras\n",
    "vgg = VGG19(weights=\"imagenet\", include_top=False)\n",
    "vgg.trainable = False\n",
    "loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block3_conv3\").output)\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(loss_model(y_true) - loss_model(y_pred)))\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return 0.4 * tf.keras.losses.MeanSquaredErr()(y_true, y_pred) + 0.3 * ssim_loss(y_true, y_pred) +  0.3 * perceptual_loss(y_true, y_pred)\n",
    "\n",
    "# Format Keras\n",
    "model = load_model(\"C:/Users/TALITA/SSSKRIPPPSI/mlp_cnn_model100.keras\", custom_objects={\n",
    "    'combined_loss': combined_loss,\n",
    "    'perceptual_loss': perceptual_loss,\n",
    "    'ssim_loss': ssim_loss\n",
    "})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dd6e2",
   "metadata": {},
   "source": [
    "## Percobaan dengan data eksperimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_eks = \"-\"\n",
    "\n",
    "Eks_list = []\n",
    "epsilon = 1e-6\n",
    "file_names = []\n",
    "for file_name in os.listdir(folder_eks):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder_eks, file_name)\n",
    "        data = pd.read_excel(file_path, header=None).to_numpy().flatten()\n",
    "        data = data.reshape(-1, 1)  # reshape ke 2D\n",
    "        data_scaled = (data - np.mean(data))/ np.mean(data)\n",
    "        data_norm = data_scaled/np.max(data_scaled)\n",
    "        Eks_list.append(data_scaled)  # flatten lagi supaya array 1D\n",
    "        file_names.append(file_name)\n",
    "\n",
    "# Gabungkan semua data\n",
    "Eks = np.array(Eks_list)\n",
    "# Jika model butuh input shape tertentu, sesuaikan\n",
    "print(\"Eks shape:\", Eks.shape)  # (jumlah_sample, fitur)\n",
    "print(Eks[1])\n",
    "\n",
    "# Prediksi\n",
    "C = model.predict(Eks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan 3 hasil prediksi\n",
    "num_display = 3\n",
    "plt.figure(figsize=(10, 3 * num_display))\n",
    "\n",
    "for i in range(num_display):\n",
    "    plt.subplot(num_display, 1, i+1)\n",
    "    plt.imshow(C[i], cmap='jet')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Hasil Rekonstruksi: {file_names[i]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bbf059",
   "metadata": {},
   "source": [
    "# Dashboard untuk menampilkan semua hasil dari MLP-CNN dan perbandingannya dengan Linear Satu Langkah, pisah dan jalankan di file tersendiri untuk dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import time\n",
    "fm PIL import Image\n",
    "fm sklearn.model_selection import train_test_split\n",
    "fm sklearn.prepcessing import MinMaxScaler\n",
    "fm skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "fm skimage.metrics import structural_similarity as ssim\n",
    "fm tensorflow.keras.applications import VGG19\n",
    "fm tensorflow.keras.models import load_model, Model\n",
    "\n",
    "# Judul dan sidebar\n",
    "st.set_page_config(page_title=\"MLP-CNN Image Reconstruction Dashboard\", layout=\"wide\")\n",
    "st.title(\"🔍 MLP-CNN Image Reconstruction Dashboard\")\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    /* Ubah backgund keseluruhan */\n",
    "    .stApp {\n",
    "        backgund-color: #f5f7fb;\n",
    "            font-family: 'Segoe UI', sans-serif;\n",
    "    }\n",
    "\n",
    "    /* Ubah warna judul */\n",
    "    h1, h2, h3 {\n",
    "        color: #1f3b75;\n",
    "    }\n",
    "\n",
    "    /* Styling untuk kotak metric */\n",
    "    div[data-testid=\"metric-container\"] {\n",
    "        backgund-color: #ffffff;\n",
    "        border: 1px solid #dfe4ea;\n",
    "        padding: 15px;\n",
    "        border-radius: 12px;\n",
    "        box-shadow: 1px 1px 5px rgba(0,0,0,0.03);\n",
    "        margin-bottom: 10px;\n",
    "    }\n",
    "\n",
    "    /* Warna teks label metric */\n",
    "    div[data-testid=\"metric-container\"] label {\n",
    "        color: #1f3b75;\n",
    "        font-weight: 600;\n",
    "        font-size: 13px;\n",
    "    }\n",
    "    button {\n",
    "        border-radius: 6px !important\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Timeout durasi (dalam detik)\n",
    "TIMEOUT_SECONDS = 600  # misalnya auto-mati dalam 60 detik jika tidak ada aktivitas\n",
    "\n",
    "# Timestamp global yang akan diperbarui setiap rerun\n",
    "last_active = time.time()\n",
    "\n",
    "# Fungsi watchdog yang akan menghentikan pses jika timeout\n",
    "def timeout_watcher():\n",
    "    global last_active\n",
    "    while True:\n",
    "        time.sleep(10)  # Cek setiap 10 detik\n",
    "        if time.time() - last_active > TIMEOUT_SECONDS:\n",
    "            print(\"❌ Tidak ada aktivitas Streamlit. Menutup aplikasi...\")\n",
    "            os._exit(0)  # Paksa hentikan pses Python\n",
    "\n",
    "# Jalankan watcher sekali saja saat script pertama kali dijalankan\n",
    "if \"watchdog_started\" not in st.session_state:\n",
    "    threading.Thread(target=timeout_watcher, daemon=True).start()\n",
    "    st.session_state.watchdog_started = True\n",
    "\n",
    "# Update waktu aktif setiap ada interaksi\n",
    "last_active = time.time()\n",
    "\n",
    "# === Berikut ini isi dashboard Streamlit ===\n",
    "st.write(\"Dashboard ini akan otomatis tertutup jika tidak ada aktivitas selama 10 menit.\")\n",
    "st.button(\"Klik Aku Untuk Reset Timer\")\n",
    "\n",
    "# Navigasi\n",
    "st.sidebar.header(\"Navigasi Dashboard\")\n",
    "section = st.sidebar.radio(\"Pilih Tampilan\", [\n",
    "    \"📁 Dataset & Informasi\",\n",
    "    \"🖼️ Rekonstruksi Citra\",\n",
    "    \"📊 Evaluasi Kualitas\",\n",
    "    \"🧾 Ringkasan Model\"\n",
    "])\n",
    "\n",
    "if st.sidebar.button(\"🔄 Reset Cache Dataset\"):\n",
    "    st.session_state.reset_dataset = True\n",
    "    st.cache_data.clear()\n",
    "    st.rerun()\n",
    "\n",
    "# ==============================\n",
    "# CACHE DATASET\n",
    "# ==============================\n",
    "@st.cache_data()\n",
    "def load_dataset():\n",
    "    cache_file = \"dataset_cache.npz\"\n",
    "\n",
    "    if \"reset_dataset\" in st.session_state and st.session_state.reset_dataset:\n",
    "        if os.path.exists(cache_file):\n",
    "            os.remove(cache_file)\n",
    "        st.session_state.reset_dataset = False\n",
    "\n",
    "    if os.path.exists(cache_file):\n",
    "        data = np.load(cache_file)\n",
    "        return data[\"G1\"], data[\"images\"], data[\"images2\"]\n",
    "    \n",
    "    folder1_path = \"C:/Users/TALITA/SSSKRIPPPSI/dataset/anom\"\n",
    "    folder2_path = \"C:/Users/TALITA/SSSKRIPPPSI/dataset/gambar_ori\"\n",
    "    foldergmb2_path = \"C:/Users/TALITA/SSSKRIPPPSI/gambar_rekonstruksi/gambar_rekonstruksi\"\n",
    "    \n",
    "    # Load file Excel (anomali)\n",
    "    G1_list = []\n",
    "    for file_name in os.listdir(folder1_path):\n",
    "        if file_name.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(folder1_path, file_name)\n",
    "            data = pd.read_excel(file_path, header=None).to_numpy().flatten()\n",
    "            G1_list.append(data.reshape(-1, 1))\n",
    "    G1 = np.array(G1_list).squeeze()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # G1 = scaler.fit_transform(G1a)\n",
    "\n",
    "    # Load gambar (Objek Asli)\n",
    "    image_list = []\n",
    "    for filename in os.listdir(folder2_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(folder2_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (100, 100))\n",
    "            img = img / 255.0\n",
    "            image_list.append(img)\n",
    "    image_array = np.array(image_list)\n",
    "\n",
    "    # Load gambar (Linear Satu Langkah)\n",
    "    image2_list = []\n",
    "    for filename in sorted(os.listdir(foldergmb2_path)):\n",
    "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(foldergmb2_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (100, 100))\n",
    "            img = img / 255.0\n",
    "            if img is not None:\n",
    "                image2_list.append(img)\n",
    "    image2_array = np.array(image2_list)\n",
    "\n",
    "    np.savez(cache_file, G1=G1, images=image_array, images2=image2_array)\n",
    "    return G1, image_array, image2_array\n",
    "\n",
    "G1, image_array, image2_array = load_dataset()\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(G1, image_array, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(image_array, image2_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# =============================\n",
    "# MODEL MLP-CNN\n",
    "# =============================\n",
    "if \"model\" not in st.session_state:\n",
    "    vgg = VGG19(weights=\"imagenet\", include_top=False)\n",
    "    vgg.trainable = False\n",
    "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block3_conv3\").output)\n",
    "\n",
    "    def perceptual_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.abs(loss_model(y_true) - loss_model(y_pred)))\n",
    "    def ssim_loss(y_true, y_pred):\n",
    "        return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "    def combined_loss(y_true, y_pred):\n",
    "        return 0.4 * tf.keras.losses.MeanSquaredErr()(y_true, y_pred) + 0.3 * ssim_loss(y_true, y_pred) +  0.3 * perceptual_loss(y_true, y_pred)\n",
    "\n",
    "    st.session_state.model = load_model(\n",
    "        \"C:/Users/TALITA/SSSKRIPPPSI/mlp_cnn_model100.keras\",\n",
    "        custom_objects={\n",
    "            'combined_loss': combined_loss,\n",
    "            'perceptual_loss': perceptual_loss,\n",
    "            'ssim_loss': ssim_loss\n",
    "        }\n",
    "    )\n",
    "model = st.session_state.model\n",
    "\n",
    "# =============================\n",
    "# CACHE PREDIKSI\n",
    "# =============================\n",
    "@st.cache_data()\n",
    "def get_predictions():\n",
    "    return model.predict(X_test1)\n",
    "Y_pred_sample = get_predictions()\n",
    "\n",
    "# =============================\n",
    "# CACHE HISTORY\n",
    "# =============================\n",
    "@st.cache_data()\n",
    "def load_history():\n",
    "    with open(\"C:/Users/TALITA/SSSKRIPPPSI/history.pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# =============================\n",
    "# CACHE METRIK SSIM/PSNR\n",
    "# =============================\n",
    "@st.cache_data()\n",
    "def compute_metrics(Y_true, Y_pred):\n",
    "    ssim_scores, psnr_scores = [], []\n",
    "    for y_true, y_pred in zip(Y_true, Y_pred):\n",
    "        if y_pred.shape[-1] == 1:\n",
    "            y_pred = np.repeat(y_pred, 3, axis=-1)\n",
    "        if y_true.shape[-1] == 1:\n",
    "            y_true = np.repeat(y_true, 3, axis=-1)\n",
    "        ssim_score = ssim(y_true, y_pred, channel_axis=-1, data_range=1.0)\n",
    "        psnr_score = psnr(y_true, y_pred, data_range=1.0)\n",
    "        ssim_scores.append(ssim_score)\n",
    "        psnr_scores.append(psnr_score)\n",
    "    return ssim_scores, psnr_scores\n",
    "\n",
    "# =============================\n",
    "# 1. Dataset & Informasi\n",
    "# =============================\n",
    "if section == \"📁 Dataset & Informasi\":\n",
    "    st.subheader(\"📁 Informasi Dataset\")\n",
    "\n",
    "    with st.spinner(\"📂 Memuat dataset...\"):\n",
    "        G1, image_array, image2_array = load_dataset()\n",
    "\n",
    "    st.markdown(f\"\"\"\n",
    "    - Jumlah objek numerik: **{len(G1)}**\n",
    "    - Jumlah objek asli: **{len(image_array)}**\n",
    "    - Ukuran citra: **{image_array[0].shape if len(image_array) > 0 else '(kosong)'}**\n",
    "    - Dimensi fitur input: **{G1.shape}**\n",
    "    \"\"\")\n",
    "\n",
    "    # Contoh data\n",
    "    st.write(\"📊 Contoh Data Objek Numerik (fitur):\")\n",
    "    st.dataframe(pd.DataFrame(G1[:7]).style.format(\"{:.6f}\"))\n",
    "\n",
    "    st.write(\"🖼️ Contoh Data Objek Asli:\")\n",
    "    st.image(image_array[:7], width=100, caption=[f\"Sampel {i}\" for i in range(7)])\n",
    "\n",
    "# =============================\n",
    "# 2. Rekonstruksi Citra\n",
    "# =============================\n",
    "elif section == \"🖼️ Rekonstruksi Citra\":\n",
    "    st.subheader(\"🖼️ Perbandingan Citra Asli vs Rekonstruksi\")\n",
    "    st.markdown(\"Contoh hasil prediksi dari model:\")\n",
    "    num_samples = len(X_test1)\n",
    "    idx = st.slider(\"🔢 Pilih Index Sampel Uji\", 0, num_samples - 1, 0)\n",
    "\n",
    "    # Ambil data satu sampel\n",
    "    X_sample = X_test1[idx:idx+1]\n",
    "    Y_true = Y_test1[idx]\n",
    "    Y_pred = model.predict(X_sample)[0]\n",
    "    Y_pred = np.clip(Y_pred, 0, 1)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    # Validasi shape dan channel\n",
    "    if Y_true.ndim == 2:\n",
    "        Y_true = np.stack([Y_true]*3, axis=-1)\n",
    "    if Y_pred.ndim == 2:\n",
    "        Y_pred = np.stack([Y_pred]*3, axis=-1)\n",
    "    elif Y_pred.shape[-1] == 1:\n",
    "        Y_pred = np.repeat(Y_pred, 3, axis=-1)\n",
    "\n",
    "    # Pastikan nilai dalam rentang 0-1\n",
    "    Y_true = np.clip(Y_true, 0, 1)\n",
    "    Y_pred = np.clip(Y_pred, 0, 1)\n",
    "\n",
    "    # Hitung metrik\n",
    "    ssim_score = ssim(Y_true, Y_pred, channel_axis=2, data_range=1.0)\n",
    "    psnr_score = psnr(Y_true, Y_pred, data_range=1.0)\n",
    "    mse_score = np.mean((Y_true - Y_pred) ** 2)\n",
    "\n",
    "    # Tampilkan metrik\n",
    "    col_m1, col_m2, col_m3 = st.columns(3)\n",
    "    col_m1.metric(\"MSE\", f\"{mse_score:.4f}\")\n",
    "    col_m2.metric(\"🔍 SSIM\", f\"{ssim_score:.4f}\")\n",
    "    col_m3.metric(\"📏 PSNR\", f\"{psnr_score:.2f} dB\")\n",
    "\n",
    "    # Tampilkan gambar asli dan hasil prediksi\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.image(Y_true, caption=\"🎯 Target (Asli)\", width=200)\n",
    "    with col2:\n",
    "        st.image(Y_pred, caption=\"🧠 Prediksi (Model)\", width=200)\n",
    "    \n",
    "    st.subheader(\"🔍 Perbandingan Citra Asli vs Rekonstruksi Linear Satu Langkah vs Rekonstruksi MLP-CNN\")\n",
    "    # Slider untuk pilih indeks gambar\n",
    "    img_idx = st.slider(\"Pilih indeks gambar\", 0, num_samples - 1, 0)\n",
    "\n",
    "    # Ambil 1 gambar dari setiap jenis\n",
    "    with st.spinner(\"🔍 Menghasilkan prediksi semua citra dengan MLP-CNN...\"):\n",
    "        Y_pred_all = model.predict(X_test1)\n",
    "        Y_pred_all = np.clip(Y_pred_all, 0, 1)\n",
    "    img_asli = Y_test1[img_idx]\n",
    "    img_linear = Y_test2[img_idx]\n",
    "    img_cnn = Y_pred_all[img_idx]\n",
    "\n",
    "    # Konversi ke RGB kalau channel-nya cuma 1\n",
    "    if img_asli.shape[-1] == 1:\n",
    "        img_asli = np.repeat(img_asli, 3, axis=-1)\n",
    "    if img_cnn.shape[-1] == 1:\n",
    "        img_cnn = np.repeat(img_cnn, 3, axis=-1)\n",
    "    if img_linear.shape[-1] == 1:\n",
    "        img_linear = np.repeat(img_linear, 3, axis=-1)\n",
    "\n",
    "    # Hitung metrik untuk linear\n",
    "    mse_linear = np.mean((img_asli - img_linear) ** 2)\n",
    "    ssim_linear = ssim(img_asli, img_linear, channel_axis=2, data_range=1.0)\n",
    "    psnr_linear = psnr(img_asli, img_linear, data_range=1.0)\n",
    "\n",
    "    # Hitung metrik untuk MLP-CNN\n",
    "    mse_cnn = np.mean((img_asli - img_cnn) ** 2)\n",
    "    ssim_cnn = ssim(img_asli, img_cnn, channel_axis=2, data_range=1.0)\n",
    "    psnr_cnn = psnr(img_asli, img_cnn, data_range=1.0)\n",
    "\n",
    "    # Tampilkan 3 gambar sejajar\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        st.image(img_asli, caption=\"Citra Asli\", width=180)\n",
    "        st.write(\" \")\n",
    "    with col2:\n",
    "        st.image(img_linear, caption=\"Linear Satu Langkah\", width=180)\n",
    "        st.markdown(f\"MSE: `{mse_linear:.4f}`  \\nSSIM: `{ssim_linear:.4f}`  \\nPSNR: `{psnr_linear:.2f} dB`\")\n",
    "    with col3:\n",
    "        st.image(img_cnn, caption=\"MLP-CNN\", width=180)\n",
    "        st.markdown(f\"MSE: `{mse_cnn:.4f}`  \\nSSIM: `{ssim_cnn:.4f}`  \\nPSNR: `{psnr_cnn:.2f} dB`\")\n",
    "\n",
    "# =============================\n",
    "# 3. Evaluasi Kualitas\n",
    "# =============================\n",
    "elif section == \"📊 Evaluasi Kualitas\":\n",
    "    st.subheader(\"📊 Evaluasi Rekonstruksi\")\n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "    **Loss dan MSE (Mean Squared Err)** menunjukkan performa model selama pelatihan. Kurva menurun dan stabil mencerminkan pembelajaran yang baik.\n",
    "                \n",
    "    **SSIM (Structural Similarity Index)** mengukur kemiripan struktural antara citra asli dan hasil rekonstruksi — semakin mendekati 1, semakin mirip.\n",
    "\n",
    "    **PSNR (Peak Signal-to-Noise Ratio)** mengukur kualitas rekonstruksi terhadap citra asli — semakin tinggi nilai dB, semakin baik kualitasnya.\n",
    "    \"\"\")\n",
    "\n",
    "    history = load_history()\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    mse = history['mse']\n",
    "    val_mse = history['val_mse']\n",
    "\n",
    "    # Hitung metrik prediksi\n",
    "    Y_pred_sample = get_predictions()\n",
    "    Y_pred_sample = np.clip(Y_pred_sample, 0, 1)\n",
    "\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "\n",
    "    for y_true, y_pred in zip(Y_test1, Y_pred_sample):\n",
    "        if y_pred.shape[-1] == 1:\n",
    "            y_pred = np.repeat(y_pred, 3, axis=-1)\n",
    "        if y_true.shape[-1] == 1:\n",
    "            y_true = np.repeat(y_true, 3, axis=-1)\n",
    "\n",
    "        ssim_score = ssim(y_true, y_pred, channel_axis=-1, data_range=1.0, win_size=11)\n",
    "        psnr_score = psnr(y_true, y_pred, data_range=1.0)\n",
    "\n",
    "        ssim_scores.append(ssim_score)\n",
    "        psnr_scores.append(psnr_score)\n",
    "\n",
    "    # ============================\n",
    "    # Visualisasi dalam 1 kolom\n",
    "    # ============================\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"📉 Loss\", \"📉 MSE\", \"📊 SSIM\", \"📊 PSNR\"])\n",
    "    with tab1:\n",
    "        st.markdown(\"**📉 Loss**\")\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.plot(loss, label='Training Loss', color='blue')\n",
    "        ax1.plot(val_loss, label='Validation Loss', color='orange')\n",
    "        ax1.set_title('Loss vs Epoch')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        st.pyplot(fig1)\n",
    "    with tab2:\n",
    "        st.markdown(\"**📉 MSE**\")\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        ax2.plot(mse, label='Training MSE', color='green')\n",
    "        ax2.plot(val_mse, label='Validation MSE', color='red')\n",
    "        ax2.set_title('MSE vs Epoch')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Mean Squared Err')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        st.pyplot(fig2)\n",
    "    with tab3:\n",
    "        st.metric(\"Rata-rata SSIM\", f\"{np.mean(ssim_scores):.4f}\")\n",
    "        st.markdown(\"**📊 Histogram SSIM**\")\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        ax3.hist(ssim_scores, bins=20, color='skyblue', edgecolor='black')\n",
    "        ax3.set_title(\"Distribusi SSIM\")\n",
    "        ax3.set_xlabel(\"SSIM\")\n",
    "        ax3.set_ylabel(\"Frekuensi\")\n",
    "        st.pyplot(fig3)\n",
    "    with tab4:\n",
    "        st.metric(\"Rata-rata PSNR\", f\"{np.mean(psnr_scores):.2f} dB\")\n",
    "        st.markdown(\"**📊 Histogram PSNR**\")\n",
    "        fig4, ax4 = plt.subplots()\n",
    "        ax4.hist(psnr_scores, bins=20, color='salmon', edgecolor='black')\n",
    "        ax4.set_title(\"Distribusi PSNR\")\n",
    "        ax4.set_xlabel(\"PSNR (dB)\")\n",
    "        ax4.set_ylabel(\"Frekuensi\")\n",
    "        st.pyplot(fig4)\n",
    "\n",
    "# =============================\n",
    "# 4. Ringkasan Model\n",
    "# =============================\n",
    "elif section == \"🧾 Ringkasan Model\":\n",
    "    st.subheader(\"🧾 Arsitektur & Konfigurasi Model\")\n",
    "    st.markdown(\"\"\"\n",
    "    - **Encoder**: MLP\n",
    "    - **Decoder**: CNN\n",
    "    - **Loss Function**:\n",
    "        - 40% MSE\n",
    "        - 30% SSIM Loss\n",
    "        - 30% Perceptual Loss (VGG19)\n",
    "    \"\"\")\n",
    "\n",
    "    image = Image.open(\"C:/Users/TALITA/Downloads/Cobalagi2.drawio.png\")\n",
    "    st.image(image, caption=\"Diagram Arsitektur Model MLP-CNN\", use_container_width=True)\n",
    "    # st.text(model.summary()) atau model.summary(print_fn=...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
